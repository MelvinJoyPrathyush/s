import concurrent.futures
import multiprocessing
import time

catalog_name = "cortex_dev_catalog"
max_threads = min(16, multiprocessing.cpu_count())  # Limit to avoid overloading Spark

def get_views_for_schema(catalog, schema):
    """Retrieve views from a specific schema and annotate them with the schema name."""
    try:
        views_query = f"SHOW VIEWS IN {catalog}.{schema}"
        df = spark.sql(views_query)
        # Add schema as metadata to each view
        return [row.asDict() | {"schema": schema} for row in df.collect()]
    except Exception as e:
        print(f"✘ Error processing schema {schema}: {str(e)}")
        return []

# Step 1: Get all schemas in the catalog
schemas_df = spark.sql(f"SHOW SCHEMAS IN {catalog_name}")
schemas = [row['databaseName'] for row in schemas_df.collect()]

# Step 2: Filter schemas containing 'raw' or 'cdm'
filtered_schemas = [s for s in schemas if 'raw' in s.lower() or 'cdm' in s.lower()]

print(f"🔍 Total schemas found: {len(schemas)}")
print(f"✅ Filtered schemas (raw/cdm): {len(filtered_schemas)}")
print(f"⚙ Using up to {max_threads} threads\n")

# Step 3: Parallel retrieval of views
start_time = time.time()
views = []

with concurrent.futures.ThreadPoolExecutor(max_workers=max_threads) as executor:
    future_to_schema = {
        executor.submit(get_views_for_schema, catalog_name, schema): schema
        for schema in filtered_schemas
    }

    for future in concurrent.futures.as_completed(future_to_schema):
        schema = future_to_schema[future]
        try:
            schema_views = future.result()
            views.extend(schema_views)
            print(f"[{time.strftime('%H:%M:%S')}] ✔ Processed {schema}: {len(schema_views)} views")
        except Exception as exc:
            print(f"[{time.strftime('%H:%M:%S')}] ✘ Failed for schema {schema}: {exc}")

elapsed = time.time() - start_time
print(f"\n✅ Completed in {elapsed:.2f} seconds")
print(f"📦 Total views found: {len(views)}")

# Step 4: Create DataFrame
if views:
    views_df = spark.createDataFrame(views)
    views_df = views_df.orderBy("schema", "viewName")  # Adjust column names if needed
    display(views_df)
else:
    print("⚠ No views were found in the filtered schemas.")
